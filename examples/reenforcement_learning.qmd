---
title: "Reenforcement Learning"
format: 
    html:
        embed-resources: true
---

# Simple Game: Rock Paper Scissors

```{python}

import random
import numpy as np

def points(player, opponent):
    if player == opponent:
        return 0
    if player == "rock" and opponent == "scissors":
        return 1
    if player == "scissors" and opponent == "paper":
        return 1
    if player == "paper" and opponent == "rock":
        return 1
    return -1

def points_bias(ind, bias):
    vec = [0.0, 0.0, 0.0]
    for (i, v) in enumerate(vec):
        if i == ind:
            vec[i] = 1 / 3 + bias
        else:
            vec[i] = 1 / 3 - bias / 2
    return vec

def beats_move(move):
    if move == "rock":
        return "paper"
    if move == "paper":
        return "scissors"
    if move == "scissors":
        return "rock"
    return None


OPTIONS = ["rock", "paper", "scissors"]

def human_player(last_move, last_opponent_move, bias = 0.33):
    if last_move == None:
        return random.choice(OPTIONS)

    last_points = points(last_move, last_opponent_move)
    if last_points == 1:
        wv = points_bias(OPTIONS.index(last_move), bias)
    elif last_points == -1:
        wv = points_bias(OPTIONS.index(last_opponent_move), bias)
    else:
        wv = points_bias(OPTIONS.index(last_move), 0.0)
    
    return random.choices(OPTIONS, weights = wv)[0]


def computer_player(last_move, last_opponent_move, M):
    if last_move == None:
        return random.choice(OPTIONS)

    ind1 = OPTIONS.index(last_move)
    ind2 = OPTIONS.index(last_opponent_move)
    wv = M[ind1, ind2, :]
    return random.choices(OPTIONS, weights = wv)[0]

def perturb_M(M, epsilon = 0.01):
    inds = np.random.randint(0, 3, 2)
    v = M[inds[0], inds[1], :]
    v = v + np.random.normal(0, epsilon, 3)
    v = np.clip(v, 0, 1)
    M[inds[0], inds[1], :] = v / np.sum(v)
    return M



def play_game(M, rounds = 10000):
    human_move = None
    computer_move = None
    score = 0
    for i in range(rounds):
        computer_move_new = computer_player(computer_move, human_move, M)
        human_move_new = human_player(human_move, computer_move)
        computer_move = computer_move_new
        human_move = human_move_new
        score += points(computer_move, human_move)
    return score / rounds



M = np.ones((3, 3, 3)) / 3
print(play_game(M))


M_old = M.copy()
M_original = M.copy()

for i in range(10000):
    M = perturb_M(M_old.copy())
    pm = play_game(M)
    pmo = play_game(M_old)
    # print(M - M_old)
    # assert 1 == 2
    if pm > pmo:
        M_old = M.copy()
    if i % 100 == 0:
        print(i, pm, pmo)
        # print("Accepted")
    # print(pm)



print(play_game(M))




        
    

    
    


```